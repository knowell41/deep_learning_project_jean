{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8e9cbc",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc246e83",
   "metadata": {},
   "source": [
    "### Machine Setup\n",
    "<p><b>OS</b>: Ubuntu <br></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5de9a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f964840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbc3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                            shear_range = 0.2,\n",
    "                            zoom_range = 0.2,\n",
    "                            horizontal_flip = True,\n",
    "                            validation_split = 0.3)\n",
    "\n",
    "\n",
    "training_set = datagen.flow_from_directory(\"dataset/archive\",\n",
    "                                        subset='training',\n",
    "                                        target_size = (64, 64),\n",
    "                                        batch_size = 32\n",
    "                                       )\n",
    "validation_set = datagen.flow_from_directory(\"dataset/archive\",\n",
    "                                        subset='validation',\n",
    "                                        target_size = (64, 64),\n",
    "                                        batch_size = 32\n",
    "                                       )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = training_set.class_indices\n",
    "class_names = {class_names[i]:i for i in class_names.keys()}\n",
    "print(class_names)\n",
    "train_imgs, labels = next(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567087b5",
   "metadata": {},
   "source": [
    "### Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to automate addition of hidden layers\n",
    "from keras_visualizer import visualizer\n",
    "from IPython.display import Image\n",
    "def cnn_model(hidden_layer=1):\n",
    "    cnn = tf.keras.models.Sequential()\n",
    "    \n",
    "    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "    cnn.add(tf.keras.layers.BatchNormalization())\n",
    "    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    cnn.add(tf.keras.layers.Dropout(0.2))\n",
    "    \n",
    "    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "    cnn.add(tf.keras.layers.BatchNormalization())\n",
    "    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    cnn.add(tf.keras.layers.Dropout(0.2))\n",
    "    \n",
    "    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "    cnn.add(tf.keras.layers.BatchNormalization())\n",
    "    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    cnn.add(tf.keras.layers.Dropout(0.2))\n",
    "    \n",
    "    cnn.add(tf.keras.layers.Flatten())\n",
    "    for layer in range(hidden_layer):\n",
    "        cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "    cnn.add(tf.keras.layers.Dense(units=2, activation='softmax'))\n",
    "    cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d4e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automate the hidden layer count\n",
    "cnn1 = cnn_model(hidden_layer=1)\n",
    "cnn2 = cnn_model(hidden_layer=3)\n",
    "cnn3 = cnn_model(hidden_layer=5)\n",
    "cnn4 = cnn_model(hidden_layer=7)\n",
    "cnn5 = cnn_model(hidden_layer=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3b424",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize cnn model with 1 hidden layer\n",
    "history1 = cnn1.fit(x = training_set, validation_data = validation_set, epochs = 50, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4269ec3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize cnn model with 3 hidden layer\n",
    "history2 = cnn2.fit(x = training_set, validation_data = validation_set, epochs = 50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873fd44",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize cnn model with 5 hidden layer\n",
    "history3 = cnn3.fit(x = training_set, validation_data = validation_set, epochs = 50, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cnn model with 7 hidden layer\n",
    "history4 = cnn4.fit(x = training_set, validation_data = validation_set, epochs = 50, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d51cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cnn model with 9 hidden layer\n",
    "history5 = cnn5.fit(x = training_set, validation_data = validation_set, epochs = 50, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2c9da",
   "metadata": {},
   "source": [
    "## Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd429864",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDf1 = pd.DataFrame.from_dict(history1.history)\n",
    "historyDf1[\"epoch\"] = np.arange(historyDf1.shape[0])\n",
    "\n",
    "historyDf2 = pd.DataFrame.from_dict(history2.history)\n",
    "historyDf2[\"epoch\"] = np.arange(historyDf2.shape[0])\n",
    "\n",
    "historyDf3 = pd.DataFrame.from_dict(history3.history)\n",
    "historyDf3[\"epoch\"] = np.arange(historyDf3.shape[0])\n",
    "\n",
    "historyDf4 = pd.DataFrame.from_dict(history4.history)\n",
    "historyDf4[\"epoch\"] = np.arange(historyDf4.shape[0])\n",
    "\n",
    "historyDf5 = pd.DataFrame.from_dict(history5.history)\n",
    "historyDf5[\"epoch\"] = np.arange(historyDf5.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e0260",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cb53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ab0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization function\n",
    "\n",
    "def viz(title, df, sizex, sizey):\n",
    "    fig = px.scatter(title=f\"Accuracy score of Model with {title} Hidden Layer\", \n",
    "                 x=[0], y=[0], width=int(sizex), height=int(sizey),\n",
    "                 labels= {\"x\":\"Epoch\",\"y\":\"Accuracy\"})\n",
    "    fig.add_trace(go.Scatter(x=df[\"epoch\"], \n",
    "                             y=df[\"accuracy\"], \n",
    "                             mode=\"lines\",\n",
    "                             name=\"Training Accuracy\"))\n",
    "    fig.add_trace(go.Scatter(x=df[\"epoch\"], \n",
    "                             y=df[\"val_accuracy\"], \n",
    "                             mode=\"lines\", \n",
    "                             name=\"Validation Accuracy\"))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig = px.scatter(title=f\"Loss score of Model with {title} Hidden Layer\", \n",
    "                     x=[0], y=[0], width=int(sizex), height=int(sizey),\n",
    "                     labels= {\"x\":\"Epoch\",\"y\":\"Loss\"})\n",
    "    fig.add_trace(go.Scatter(x=df[\"epoch\"], \n",
    "                             y=df[\"accuracy\"], \n",
    "                             mode=\"lines\",\n",
    "                             name=\"Training Loss\"))\n",
    "    fig.add_trace(go.Scatter(x=df[\"epoch\"], \n",
    "                             y=df[\"val_loss\"], \n",
    "                             mode=\"lines\", \n",
    "                             name=\"Validation Loss\"))\n",
    "\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d329a6",
   "metadata": {},
   "source": [
    "### 1 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79333cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDf1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(\"1\", historyDf1, 500, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639ff88",
   "metadata": {},
   "source": [
    "## 3 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e40414",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDf2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa9d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(\"3\", historyDf2, 500, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb098c",
   "metadata": {},
   "source": [
    "## 5 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398df4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDf3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664b52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(\"5\", historyDf3, 500, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd9ee5",
   "metadata": {},
   "source": [
    "## 7 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eed16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDf4.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(\"7\", historyDf4, 500, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dadbd6",
   "metadata": {},
   "source": [
    "## 9 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f79d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDf5.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(\"9\", historyDf5, 500, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115c421",
   "metadata": {},
   "source": [
    "## Export the best trained model to file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "cnn2.save(\"cnnModel_mask-nomask.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef1fb0",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "\n",
    "A new starting point of testing after training the model.\n",
    "Model can be used to classify without the need of re-running the training sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912a76a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-25 23:39:48.685000: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-09-25 23:39:48.685116: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (DESKTOP-I4FO2JM): /proc/driver/nvidia/version does not exist\n",
      "2021-09-25 23:39:48.687069: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "loadCNN = load_model(\"cnnModel_mask-nomask.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dee238f",
   "metadata": {},
   "source": [
    "### Pediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d45d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_button_clicked(_):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        try:\n",
    "            imagepath = f\"{os.getcwd()}/img.jpg\"\n",
    "            for key in uploader.value.keys():\n",
    "                filename = key\n",
    "            imgByte = uploader.value[filename]['content']\n",
    "            nparr = np.frombuffer(imgByte, np.uint8)\n",
    "            img_np = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "            RGB_img = cv2.cvtColor(img_np, cv2.COLOR_BGR2RGB)\n",
    "            imageUploaded = Image.fromarray(RGB_img)\n",
    "            cv2.imwrite(\"img.jpg\", img_np)\n",
    "        \n",
    "            test_image = image.load_img(imagepath, target_size = (64, 64))\n",
    "            test_image = image.img_to_array(test_image)\n",
    "            test_image = np.expand_dims(test_image, axis = 0)\n",
    "            result = loadCNN.predict(test_image/255.0)\n",
    "\n",
    "            result = round(result[0][0])\n",
    "#             print(result)\n",
    "            if result == 0:\n",
    "                val = \"Without Mask\"\n",
    "                display(HTML(f'<h3>{val}</h1>'))\n",
    "                imageUploaded.show()\n",
    "            else:\n",
    "                val = \"With Mask\"\n",
    "                display(HTML(f'<h3>{val}</h1>'))\n",
    "                imageUploaded.show()\n",
    "            uploader.value.clear()\n",
    "            uploader._counter = 0\n",
    "        except:\n",
    "            print(\"Upload image first!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0d616",
   "metadata": {},
   "source": [
    "### User Interaction\n",
    "For model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467d3e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "uploader = widgets.FileUpload(\n",
    "    accept=\"\",  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=False  # True to accept multiple files upload else False\n",
    ")\n",
    "\n",
    "button = widgets.Button(\n",
    "    description='Classify',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to let the model classify the uploaded image.',\n",
    "    icon='robot' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "out = widgets.Output()\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962b99d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Test the model</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c83e10843047678560f503ea366916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775eb2858f164d4e8857d5fa48b20d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Classify', icon='robot', style=ButtonStyle(), tooltip='Click to let the mod…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(HTML('<h1>Test the model</h1>'))\n",
    "display(uploader)\n",
    "display(widgets.VBox([button,out]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09b0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e9d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
